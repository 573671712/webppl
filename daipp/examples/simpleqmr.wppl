/*
This is a simple "explaining away" bayes net. It allows us to test whether the context network learns
to pass along the relevant (summary of) previous choices.

run with: ./webppl examples/simpleqmr.wppl --require ./daipp
*/

var data = [true, true]

var strengthParam = 0.8
var backgroundParam = 0.05
var noisyOrProb = function(causes,causalPowers,baserate){
  return 1-(1-baserate)*product(map2(function(c,cp){return c?(1-cp):1},causes,causalPowers))
}

var observe = function(erp,val,params){
  factor(erp.score(params, val))
}

var model = function() {

  initContext(data);   //initialize the context, incorporating the observation(s)

  var c1=sampleDaipp(bernoulliERP,[0.5])
  var c2=sampleDaipp(bernoulliERP,[0.5])
  var c3=sampleDaipp(bernoulliERP,[0.5])

  observe(bernoulliERP,data[0],[noisyOrProb([c1,c3],[strengthParam,strengthParam],backgroundParam)])
  observe(bernoulliERP,data[1],[noisyOrProb([c2,c3],[strengthParam,strengthParam],backgroundParam)])

  return [c1,c2,c3];

};


// Tutorial training.
// var erp = SMC(model, {particles: 100, saveTraces: true, ignoreGuide: true});
// var params = Optimize(model, {steps: 50, method: {gd: {stepSize: 0.1}}, estimator: {EUBO: {traces: erp.traces}}});

// VI.

var params = Optimize(model, {steps: 1000, method: {adagrad: {stepSize: 0.1}}, estimator: 'ELBO'});

SampleGuide(model, {samples: 1000, params: params});
